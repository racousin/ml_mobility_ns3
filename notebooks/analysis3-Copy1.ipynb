{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb29946-6a89-46e4-b09c-e7d1ded78738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading model...\n",
      "Loading data...\n",
      "Loading metadata and scalers...\n",
      "1. Generating and sampling data for statistical comparison...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating and Sampling:   0%|                                                                                                                                                                                                                         | 0/18 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# %% Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Union\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from ml_mobility_ns3.models.vae import ConditionalTrajectoryVAE\n",
    "from ml_mobility_ns3.utils.model_utils import load_model_from_checkpoint\n",
    "\n",
    "# %% Configuration\n",
    "MODEL_PATH = Path(\"../results/initial_run_attention/best_model.pt\")\n",
    "DATA_PATH = Path(\"../preprocessing/vae_dataset.npz\")\n",
    "PREPROCESSING_DIR = Path(\"../preprocessing/\")\n",
    "\n",
    "# --- Device setup ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% Load Model and Data\n",
    "def load_vae_model_and_data(model_path, data_path, preprocessing_dir):\n",
    "    \"\"\"Load model, data, and all necessary components.\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    model, config = load_model_from_checkpoint(model_path, device)\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    data = np.load(data_path)\n",
    "    \n",
    "    print(\"Loading metadata and scalers...\")\n",
    "    with open(preprocessing_dir / \"metadata.pkl\", 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    with open(preprocessing_dir / \"scalers.pkl\", 'rb') as f:\n",
    "        scalers = pickle.load(f)\n",
    "    \n",
    "    return model, data, metadata, scalers\n",
    "\n",
    "model, data, metadata, scalers = load_vae_model_and_data(MODEL_PATH, DATA_PATH, PREPROCESSING_DIR)\n",
    "mode_to_idx = {name: i for i, name in enumerate(metadata['transport_modes'])}\n",
    "idx_to_mode = {i: name for i, name in enumerate(metadata['transport_modes'])}\n",
    "\n",
    "# %% Data Generation and Sampling\n",
    "def generate_and_sample_datasets(\n",
    "    model: ConditionalTrajectoryVAE,\n",
    "    data: Dict[str, np.ndarray],\n",
    "    n_samples_per_mode: int = 500\n",
    ") -> (List[Dict], List[Dict]):\n",
    "    \"\"\"Generate and sample large datasets for statistical comparison.\"\"\"\n",
    "    all_generated = []\n",
    "    all_real = []\n",
    "    \n",
    "    trajectory_scaler = scalers['trajectory']\n",
    "    \n",
    "    for mode_name, mode_idx in tqdm(mode_to_idx.items(), desc=\"Generating and Sampling\"):\n",
    "        # --- Real Data ---\n",
    "        real_indices = np.where(data['transport_modes'] == mode_idx)[0]\n",
    "        if len(real_indices) > 0:\n",
    "            sample_indices = np.random.choice(real_indices, min(n_samples_per_mode, len(real_indices)), replace=False)\n",
    "            \n",
    "            for idx in sample_indices:\n",
    "                length = int(data['trip_lengths'][idx])\n",
    "                unscaled_traj = trajectory_scaler.inverse_transform(data['trajectories'][idx, :length, :])\n",
    "                all_real.append({'trajectory': unscaled_traj, 'mode': mode_name})\n",
    "                \n",
    "                # --- Generation ---\n",
    "                # Generate a trajectory of similar length to a real one\n",
    "                gen_length = length \n",
    "                \n",
    "                mode_tensor = torch.tensor([mode_idx], dtype=torch.long, device=device)\n",
    "                length_tensor = torch.tensor([gen_length], dtype=torch.long, device=device)\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    generated = model.generate(mode_tensor, length_tensor, n_samples=1, device=device)\n",
    "                \n",
    "                gen_unscaled = trajectory_scaler.inverse_transform(generated.cpu().numpy()[0, :gen_length, :])\n",
    "                all_generated.append({'trajectory': gen_unscaled, 'mode': mode_name})\n",
    "\n",
    "    return all_real, all_generated\n",
    "\n",
    "# %% Statistical Metrics Calculation\n",
    "def calculate_trajectory_stats(\n",
    "    trajectories: List[Dict], \n",
    "    data_type: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculate a set of statistical metrics for a list of trajectories.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for traj in trajectories:\n",
    "        data = traj['trajectory']\n",
    "        \n",
    "        # Calculate distances (approximate conversion to meters)\n",
    "        diffs = np.diff(data[:, :2], axis=0) * 111000\n",
    "        step_distances = np.sqrt(np.sum(diffs**2, axis=1))\n",
    "        \n",
    "        # Speeds\n",
    "        speeds = data[:, 2]\n",
    "        \n",
    "        results.append({\n",
    "            'Type': data_type,\n",
    "            'Mode': traj['mode'],\n",
    "            'Length (points)': len(data),\n",
    "            'Total Distance (m)': np.sum(step_distances),\n",
    "            'Mean Speed (m/s)': np.mean(speeds),\n",
    "            'Max Speed (m/s)': np.max(speeds),\n",
    "            'Speed Std Dev': np.std(speeds)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# %% --- Main Execution ---\n",
    "# 1. Generate and sample large datasets\n",
    "print(\"1. Generating and sampling data for statistical comparison...\")\n",
    "# Note: Increasing n_samples_per_mode gives more robust stats but takes longer.\n",
    "real_dataset, generated_dataset = generate_and_sample_datasets(model, data, n_samples_per_mode=500)\n",
    "print(f\"Created datasets with {len(real_dataset)} real and {len(generated_dataset)} generated trajectories.\")\n",
    "\n",
    "# 2. Calculate statistical metrics\n",
    "print(\"\\n2. Calculating statistical metrics...\")\n",
    "real_stats_df = calculate_trajectory_stats(real_dataset, 'Real')\n",
    "generated_stats_df = calculate_trajectory_stats(generated_dataset, 'Generated')\n",
    "combined_stats_df = pd.concat([real_stats_df, generated_stats_df])\n",
    "\n",
    "# 3. Display and Visualize Comparison\n",
    "print(\"\\n\\n--- Aggregate Statistics Comparison ---\")\n",
    "# Display mean values grouped by Type and Mode\n",
    "display_stats = combined_stats_df.groupby(['Type', 'Mode']).mean().round(2)\n",
    "print(display_stats)\n",
    "\n",
    "# --- Visualization ---\n",
    "print(\"\\n\\n3. Visualizing statistical distributions...\")\n",
    "metrics_to_plot = ['Total Distance (m)', 'Mean Speed (m/s)', 'Max Speed (m/s)']\n",
    "for metric in metrics_to_plot:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.boxplot(data=combined_stats_df, x='Mode', y=metric, hue='Type', palette='viridis')\n",
    "    plt.title(f'Comparison of {metric}', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad44cb-6789-49b0-b81a-3d5cd32d4678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
