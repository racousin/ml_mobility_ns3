{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0152d03e-500e-48a3-b9dc-41285bcfc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_mobility_ns3/models/vae.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ConditionalTrajectoryVAE(nn.Module):\n",
    "    \"\"\"LSTM-based Conditional VAE for trajectory generation with transport mode and length conditioning.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 3,  # lat, lon, speed\n",
    "        sequence_length: int = 2000,\n",
    "        hidden_dim: int = 128,\n",
    "        latent_dim: int = 32,\n",
    "        num_layers: int = 2,\n",
    "        num_transport_modes: int = 5,  # number of transport modes\n",
    "        condition_dim: int = 32,  # dimension for condition embeddings\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.num_transport_modes = num_transport_modes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Condition embeddings\n",
    "        self.transport_mode_embedding = nn.Embedding(num_transport_modes, condition_dim)\n",
    "        self.length_projection = nn.Linear(1, condition_dim)\n",
    "        \n",
    "        # Total condition dimension (transport mode + length)\n",
    "        total_condition_dim = condition_dim * 2\n",
    "        \n",
    "        # Encoder - LSTM with bidirectional processing\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        encoder_output_dim = hidden_dim * 2  # bidirectional\n",
    "        \n",
    "        # Latent space projections (include conditions)\n",
    "        self.fc_mu = nn.Linear(encoder_output_dim + total_condition_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(encoder_output_dim + total_condition_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc_latent = nn.Linear(latent_dim + total_condition_dim, hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(\n",
    "            hidden_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                if len(param.shape) >= 2:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    nn.init.uniform_(param, -0.1, 0.1)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "    \n",
    "    def get_conditions(self, transport_mode: torch.Tensor, trip_length: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Create condition embeddings from transport mode and trip length.\"\"\"\n",
    "        # Transport mode embedding\n",
    "        mode_embed = self.transport_mode_embedding(transport_mode)  # (batch, condition_dim)\n",
    "        \n",
    "        # Length embedding (normalize length and project)\n",
    "        length_normalized = trip_length.unsqueeze(-1).float() / self.sequence_length  # normalize to [0,1]\n",
    "        length_embed = self.length_projection(length_normalized)  # (batch, condition_dim)\n",
    "        \n",
    "        # Concatenate conditions\n",
    "        conditions = torch.cat([mode_embed, length_embed], dim=-1)  # (batch, condition_dim * 2)\n",
    "        return conditions\n",
    "    \n",
    "    def encode(self, x: torch.Tensor, conditions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encode trajectory to latent distribution parameters.\"\"\"\n",
    "        # LSTM encoding\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        # Concatenate forward and backward hidden states from last layer\n",
    "        h = torch.cat([h[-2], h[-1]], dim=1)  # (batch, hidden_dim * 2)\n",
    "        h = self.dropout_layer(h)\n",
    "        \n",
    "        # Concatenate with conditions\n",
    "        h_conditioned = torch.cat([h, conditions], dim=-1)\n",
    "        \n",
    "        mu = self.fc_mu(h_conditioned)\n",
    "        logvar = self.fc_logvar(h_conditioned)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Reparameterization trick.\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z: torch.Tensor, conditions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode from latent space to trajectory.\"\"\"\n",
    "        batch_size = z.size(0)\n",
    "        \n",
    "        # Concatenate latent with conditions\n",
    "        z_conditioned = torch.cat([z, conditions], dim=-1)\n",
    "        \n",
    "        # Project to hidden and create sequence\n",
    "        h = self.fc_latent(z_conditioned)\n",
    "        h = torch.tanh(h)  # Add non-linearity\n",
    "        h = h.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        \n",
    "        # Decode sequence\n",
    "        out, _ = self.decoder_lstm(h)\n",
    "        out = self.dropout_layer(out)\n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        transport_mode: torch.Tensor, \n",
    "        trip_length: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        conditions = self.get_conditions(transport_mode, trip_length)\n",
    "        mu, logvar = self.encode(x, conditions)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z, conditions)\n",
    "        return recon, mu, logvar\n",
    "    \n",
    "    def generate(\n",
    "        self, \n",
    "        transport_mode: torch.Tensor, \n",
    "        trip_length: torch.Tensor, \n",
    "        n_samples: Optional[int] = None,\n",
    "        device: str = 'cpu'\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Generate new trajectories given conditions.\"\"\"\n",
    "        if n_samples is None:\n",
    "            n_samples = transport_mode.size(0)\n",
    "            \n",
    "        conditions = self.get_conditions(transport_mode, trip_length)\n",
    "        z = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            trajectories = self.decode(z, conditions)\n",
    "        return trajectories\n",
    "    \n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get model configuration.\"\"\"\n",
    "        return {\n",
    "            'input_dim': self.input_dim,\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'num_layers': self.num_layers,\n",
    "            'num_transport_modes': self.num_transport_modes,\n",
    "            'condition_dim': self.condition_dim,\n",
    "            'dropout': self.dropout,\n",
    "        }\n",
    "\n",
    "\n",
    "def masked_vae_loss(\n",
    "    recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    mu: torch.Tensor, \n",
    "    logvar: torch.Tensor, \n",
    "    mask: torch.Tensor,\n",
    "    beta: float = 1.0\n",
    ") -> Tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    VAE loss function with masking for variable-length sequences.\n",
    "    \n",
    "    Args:\n",
    "        recon: Reconstructed trajectories (batch, seq_len, input_dim)\n",
    "        x: Original trajectories (batch, seq_len, input_dim)\n",
    "        mu: Latent mean (batch, latent_dim)\n",
    "        logvar: Latent log variance (batch, latent_dim)\n",
    "        mask: Binary mask indicating valid positions (batch, seq_len)\n",
    "        beta: Weight for KL loss\n",
    "    \"\"\"\n",
    "    # Reconstruction loss with masking (MSE)\n",
    "    diff = (recon - x) ** 2  # (batch, seq_len, input_dim)\n",
    "    \n",
    "    # Expand mask to match input dimensions\n",
    "    mask_expanded = mask.unsqueeze(-1).expand_as(diff)  # (batch, seq_len, input_dim)\n",
    "    \n",
    "    # Apply mask and compute mean over valid positions\n",
    "    masked_diff = diff * mask_expanded\n",
    "    num_valid = mask_expanded.sum()\n",
    "    recon_loss = masked_diff.sum() / (num_valid + 1e-8)  # avoid division by zero\n",
    "    \n",
    "    # KL divergence (not masked, applied to latent space)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = recon_loss + beta * kl_loss\n",
    "    \n",
    "    return loss, {\n",
    "        'loss': loss.item(),\n",
    "        'recon_loss': recon_loss.item(),\n",
    "        'kl_loss': kl_loss.item(),\n",
    "        'num_valid_points': num_valid.item()\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_trajectory_metrics(pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute trajectory-specific metrics.\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted trajectories (batch, seq_len, 3) [lat, lon, speed]\n",
    "        target: Target trajectories (batch, seq_len, 3) [lat, lon, speed]\n",
    "        mask: Binary mask (batch, seq_len)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    # Apply mask\n",
    "    mask_expanded = mask.unsqueeze(-1)\n",
    "    pred_masked = pred * mask_expanded\n",
    "    target_masked = target * mask_expanded\n",
    "    \n",
    "    # Speed MAE\n",
    "    speed_mae = torch.abs(pred_masked[:, :, 2] - target_masked[:, :, 2])\n",
    "    speed_mae = (speed_mae * mask).sum() / (mask.sum() + 1e-8)\n",
    "    \n",
    "    # Distance metrics (using lat, lon)\n",
    "    def compute_distances(traj):\n",
    "        \"\"\"Compute total and bird distances for a trajectory.\"\"\"\n",
    "        # Total distance (sum of segments)\n",
    "        lat_diff = torch.diff(traj[:, :, 0], dim=1)\n",
    "        lon_diff = torch.diff(traj[:, :, 1], dim=1)\n",
    "        segment_distances = torch.sqrt(lat_diff**2 + lon_diff**2) * 111  # rough km conversion\n",
    "        total_distance = segment_distances.sum(dim=1)\n",
    "        \n",
    "        # Bird distance (start to end)\n",
    "        valid_lengths = mask.sum(dim=1)\n",
    "        bird_distances = []\n",
    "        for i, length in enumerate(valid_lengths):\n",
    "            if length > 1:\n",
    "                start = traj[i, 0, :2]\n",
    "                end = traj[i, length-1, :2]\n",
    "                bird_dist = torch.sqrt(((end - start)**2).sum()) * 111\n",
    "                bird_distances.append(bird_dist)\n",
    "            else:\n",
    "                bird_distances.append(torch.tensor(0.0, device=traj.device))\n",
    "        \n",
    "        return total_distance, torch.stack(bird_distances)\n",
    "    \n",
    "    pred_total_dist, pred_bird_dist = compute_distances(pred_masked)\n",
    "    target_total_dist, target_bird_dist = compute_distances(target_masked)\n",
    "    \n",
    "    # Distance MAEs\n",
    "    total_dist_mae = torch.abs(pred_total_dist - target_total_dist).mean()\n",
    "    bird_dist_mae = torch.abs(pred_bird_dist - target_bird_dist).mean()\n",
    "    \n",
    "    return {\n",
    "        'speed_mae': speed_mae.item(),\n",
    "        'total_distance_mae': total_dist_mae.item(),\n",
    "        'bird_distance_mae': bird_dist_mae.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e763e95f-6aa0-441d-882c-e2c64a168ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_mobility_ns3.models.vae'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Add project to path\u001b[39;00m\n\u001b[32m      9\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../..\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_mobility_ns3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvae\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConditionalTrajectoryVAE\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device\u001b[39m():\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the best available device.\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ml_mobility_ns3.models.vae'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "from ml_mobility_ns3.models.vae import ConditionalTrajectoryVAE\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_simple(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    duration_minutes: float,\n",
    "    n_samples: int = 10,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate trajectories with specified parameters.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    # Convert duration to steps (2 seconds per step)\n",
    "    trip_length = int(duration_minutes * 60 / 2)\n",
    "    trip_length = min(trip_length, 2000)  # Cap at model max\n",
    "    \n",
    "    # Create tensors\n",
    "    mode_tensor = torch.full((n_samples,), mode_idx, dtype=torch.long).to(device)\n",
    "    length_tensor = torch.full((n_samples,), trip_length, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "    \n",
    "    return trajectories.cpu().numpy(), trip_length\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\n",
    "    \n",
    "    Args:\n",
    "        trajectories: numpy array of shape (n_samples, seq_len, n_features)\n",
    "        scaler: Either a sklearn scaler object or a dict containing scalers\n",
    "    \"\"\"\n",
    "    # Handle both scaler object and dict cases\n",
    "    if isinstance(scaler, dict):\n",
    "        # Extract the trajectory scaler from the dict\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    n_samples, seq_len, n_features = trajectories.shape\n",
    "    traj_flat = trajectories.reshape(-1, n_features)\n",
    "    traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "    return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_basic_stats(trajectories, trip_length):\n",
    "    \"\"\"Compute basic statistics for generated trajectories.\"\"\"\n",
    "    stats = []\n",
    "    \n",
    "    for i, traj in enumerate(trajectories):\n",
    "        # Only look at valid portion\n",
    "        valid_traj = traj[:trip_length]\n",
    "        \n",
    "        # Speed stats (assuming index 2 is speed in m/s)\n",
    "        speeds_ms = valid_traj[:, 2]\n",
    "        speeds_kmh = speeds_ms * 3.6\n",
    "        \n",
    "        # Distance calculation\n",
    "        if trip_length > 1:\n",
    "            lat_diff = np.diff(valid_traj[:, 0])\n",
    "            lon_diff = np.diff(valid_traj[:, 1])\n",
    "            # Approximate distance in km\n",
    "            distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111\n",
    "            total_distance = distances.sum()\n",
    "            \n",
    "            # Bird distance\n",
    "            start = valid_traj[0, :2]\n",
    "            end = valid_traj[trip_length-1, :2]\n",
    "            bird_distance = np.sqrt(((end - start)**2).sum()) * 111\n",
    "        else:\n",
    "            total_distance = 0\n",
    "            bird_distance = 0\n",
    "        \n",
    "        stats.append({\n",
    "            'trajectory_id': i,\n",
    "            'mean_speed_kmh': speeds_kmh.mean(),\n",
    "            'max_speed_kmh': speeds_kmh.max(),\n",
    "            'total_distance_km': total_distance,\n",
    "            'bird_distance_km': bird_distance,\n",
    "            'duration_min': trip_length * 2 / 60\n",
    "        })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Main usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed \")\n",
    "    \n",
    "    # Get device\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    # Load scalers (this returns a dict)\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    print(f\"Loaded scalers: {list(scalers.keys())}\")\n",
    "    \n",
    "    # Generate trajectories\n",
    "    transport_mode = \"CAR\"\n",
    "    duration_minutes = 20.0\n",
    "    n_samples = 5\n",
    "    \n",
    "    print(f\"\\nGenerating {n_samples} {transport_mode} trajectories of {duration_minutes} minutes...\")\n",
    "    trajectories_norm, trip_length = generate_simple(\n",
    "        model, \n",
    "        transport_mode, \n",
    "        duration_minutes, \n",
    "        n_samples, \n",
    "        device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units - pass the scalers dict (or just the trajectory scaler)\n",
    "    print(\"Converting to real units...\")\n",
    "    trajectories_real = inverse_transform_simple(trajectories_norm, scalers)\n",
    "    # Or alternatively: trajectories_real = inverse_transform_simple(trajectories_norm, scalers['trajectory'])\n",
    "    \n",
    "    # Compute stats\n",
    "    print(\"\\nComputing statistics...\")\n",
    "    stats = compute_basic_stats(trajectories_real, trip_length)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nGenerated {n_samples} trajectories:\")\n",
    "    print(f\"Trip length: {trip_length} steps ({duration_minutes} minutes)\")\n",
    "    print(\"\\nTrajectory Statistics:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'ID':>3} | {'Mean Speed':>10} | {'Max Speed':>10} | {'Total Dist':>10} | {'Bird Dist':>10}\")\n",
    "    print(f\"{'':>3} | {'(km/h)':>10} | {'(km/h)':>10} | {'(km)':>10} | {'(km)':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for stat in stats:\n",
    "        print(f\"{stat['trajectory_id']:>3} | \"\n",
    "              f\"{stat['mean_speed_kmh']:>10.1f} | \"\n",
    "              f\"{stat['max_speed_kmh']:>10.1f} | \"\n",
    "              f\"{stat['total_distance_km']:>10.2f} | \"\n",
    "              f\"{stat['bird_distance_km']:>10.2f}\")\n",
    "    \n",
    "    # Average stats\n",
    "    mean_speed = np.mean([s['mean_speed_kmh'] for s in stats])\n",
    "    mean_total_dist = np.mean([s['total_distance_km'] for s in stats])\n",
    "    mean_bird_dist = np.mean([s['bird_distance_km'] for s in stats])\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average: {mean_speed:>19.1f} | {'':>10} | {mean_total_dist:>10.2f} | {mean_bird_dist:>10.2f}\")\n",
    "    \n",
    "    # Save one trajectory example\n",
    "    print(f\"\\nFirst trajectory sample (first 5 points):\")\n",
    "    print(\"Lat, Lon, Speed (m/s)\")\n",
    "    for i in range(min(5, trip_length)):\n",
    "        point = trajectories_real[0, i]\n",
    "        print(f\"{point[0]:.6f}, {point[1]:.6f}, {point[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b20728c-db4d-46f7-ad0c-da936b351560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Loading model...\n",
      "Loading scalers...\n",
      "\n",
      "================================================================================\n",
      "Processing CAR\n",
      "================================================================================\n",
      "Found 25169 CAR trajectories\n",
      "\n",
      "Generating 25169 CAR trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "CAR COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 25,169 (weight: 10,835,238)\n",
      "  Generated trajectories: 25,169 (weight: 10,835,238)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      19.93 ± 17.29 (range: [0.07, 171.03])\n",
      "  Generated: 19.93 ± 17.29 (range: [0.07, 171.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      91.69 ± 57.93 (range: [0.02, 281.99])\n",
      "  Generated: 12.67 ± 3.16 (range: [4.86, 30.65])\n",
      "  Relative Error: 86.2%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      8.41 ± 11.45 (range: [0.00, 135.00])\n",
      "  Generated: 3.45 ± 3.14 (range: [0.01, 39.27])\n",
      "  Relative Error: 59.0%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      12.61 ± 15.71 (range: [0.00, 168.18])\n",
      "  Generated: 6.66 ± 5.10 (range: [1.60, 71.53])\n",
      "  Relative Error: 47.2%\n",
      "Sample visualization saved to: car_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing WALKING\n",
      "================================================================================\n",
      "Found 19948 WALKING trajectories\n",
      "\n",
      "Generating 19948 WALKING trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "WALKING COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 19,948 (weight: 8,243,547)\n",
      "  Generated trajectories: 19,948 (weight: 8,243,547)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      12.44 ± 13.14 (range: [0.07, 165.03])\n",
      "  Generated: 12.44 ± 13.14 (range: [0.07, 165.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      11.96 ± 9.54 (range: [0.00, 269.81])\n",
      "  Generated: 2.35 ± 0.41 (range: [-1.85, 7.28])\n",
      "  Relative Error: 80.4%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      0.68 ± 1.04 (range: [0.00, 29.64])\n",
      "  Generated: 2.42 ± 2.73 (range: [0.03, 41.27])\n",
      "  Relative Error: 257.7%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      1.40 ± 2.10 (range: [0.00, 64.07])\n",
      "  Generated: 3.76 ± 2.66 (range: [0.24, 47.75])\n",
      "  Relative Error: 169.6%\n",
      "Sample visualization saved to: walking_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing MIXED\n",
      "================================================================================\n",
      "Found 7526 MIXED trajectories\n",
      "\n",
      "Generating 7526 MIXED trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "MIXED COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 7,526 (weight: 3,040,184)\n",
      "  Generated trajectories: 7,526 (weight: 3,040,184)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      49.33 ± 28.16 (range: [0.07, 173.00])\n",
      "  Generated: 49.33 ± 28.16 (range: [0.07, 173.00])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      64.13 ± 44.12 (range: [0.09, 284.54])\n",
      "  Generated: 10.23 ± 3.27 (range: [3.34, 24.65])\n",
      "  Relative Error: 84.0%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      15.93 ± 15.13 (range: [0.00, 150.02])\n",
      "  Generated: 2.78 ± 2.45 (range: [0.08, 33.70])\n",
      "  Relative Error: 82.6%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      21.80 ± 19.46 (range: [0.00, 208.20])\n",
      "  Generated: 8.27 ± 8.71 (range: [1.09, 83.19])\n",
      "  Relative Error: 62.1%\n",
      "Sample visualization saved to: mixed_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing BIKE\n",
      "================================================================================\n",
      "Found 5979 BIKE trajectories\n",
      "\n",
      "Generating 5979 BIKE trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "BIKE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 5,979 (weight: 2,269,561)\n",
      "  Generated trajectories: 5,979 (weight: 2,269,561)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      19.93 ± 17.14 (range: [0.17, 153.03])\n",
      "  Generated: 19.93 ± 17.14 (range: [0.17, 153.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      38.79 ± 18.65 (range: [0.07, 148.33])\n",
      "  Generated: 5.52 ± 0.69 (range: [-4.44, 13.75])\n",
      "  Relative Error: 85.8%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      3.92 ± 4.42 (range: [0.00, 58.75])\n",
      "  Generated: 1.84 ± 2.14 (range: [0.04, 46.17])\n",
      "  Relative Error: 53.1%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      5.82 ± 6.31 (range: [0.00, 76.82])\n",
      "  Generated: 3.61 ± 2.89 (range: [0.91, 50.46])\n",
      "  Relative Error: 38.0%\n",
      "Sample visualization saved to: bike_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing PUBLIC_TRANSPORT\n",
      "================================================================================\n",
      "Found 9432 PUBLIC_TRANSPORT trajectories\n",
      "\n",
      "Generating 9432 PUBLIC_TRANSPORT trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "PUBLIC_TRANSPORT COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 9,432 (weight: 4,019,902)\n",
      "  Generated trajectories: 9,432 (weight: 4,019,902)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      29.36 ± 22.16 (range: [0.03, 179.03])\n",
      "  Generated: 29.36 ± 22.16 (range: [0.03, 179.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      35.89 ± 33.64 (range: [0.07, 470.56])\n",
      "  Generated: 5.88 ± 2.29 (range: [2.58, 23.78])\n",
      "  Relative Error: 83.6%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      5.89 ± 7.92 (range: [0.00, 91.79])\n",
      "  Generated: 2.01 ± 2.03 (range: [0.00, 34.50])\n",
      "  Relative Error: 65.8%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      8.79 ± 11.36 (range: [0.00, 146.82])\n",
      "  Generated: 4.36 ± 4.17 (range: [0.00, 62.39])\n",
      "  Relative Error: 50.4%\n",
      "Sample visualization saved to: public_transport_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "SUMMARY ACROSS ALL MODES\n",
      "================================================================================\n",
      "\n",
      "Complete comparison saved to: all_trajectories_comparison.csv\n",
      "\n",
      "Overall Performance Summary:\n",
      "------------------------------------------------------------\n",
      "Duration (min): Average relative error = 0.0%\n",
      "Speed (km/h): Average relative error = 84.0%\n",
      "Bird Distance (km): Average relative error = 103.6%\n",
      "Total Distance (km): Average relative error = 73.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import folium\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Import generation functions from the fixed script\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_batch_trajectories(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    trip_lengths: List[int],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate multiple trajectories in batches for efficiency.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    all_trajectories = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(trip_lengths), batch_size):\n",
    "        batch_lengths = trip_lengths[i:i+batch_size]\n",
    "        batch_size_actual = len(batch_lengths)\n",
    "        \n",
    "        # Cap lengths at model max\n",
    "        batch_lengths = [min(l, 2000) for l in batch_lengths]\n",
    "        \n",
    "        # Create tensors\n",
    "        mode_tensor = torch.full((batch_size_actual,), mode_idx, dtype=torch.long).to(device)\n",
    "        length_tensor = torch.tensor(batch_lengths, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            batch_trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "        \n",
    "        all_trajectories.append(batch_trajectories.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    return np.vstack(all_trajectories) if all_trajectories else np.array([])\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\"\"\"\n",
    "    if isinstance(scaler, dict):\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    if len(trajectories.shape) == 2:\n",
    "        # Single trajectory\n",
    "        return trajectory_scaler.inverse_transform(trajectories)\n",
    "    else:\n",
    "        # Multiple trajectories\n",
    "        n_samples, seq_len, n_features = trajectories.shape\n",
    "        traj_flat = trajectories.reshape(-1, n_features)\n",
    "        traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "        return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_trajectory_metrics(trajectory: np.ndarray, valid_length: Optional[int] = None) -> Dict:\n",
    "    \"\"\"Compute metrics for a single trajectory.\"\"\"\n",
    "    if valid_length is None:\n",
    "        # Find valid length by checking for zero padding\n",
    "        valid_mask = ~np.all(trajectory == 0, axis=1)\n",
    "        valid_length = np.sum(valid_mask)\n",
    "    \n",
    "    # Get valid portion\n",
    "    valid_traj = trajectory[:valid_length]\n",
    "    \n",
    "    # Duration in minutes (2 seconds per point)\n",
    "    duration_min = valid_length * 2 / 60\n",
    "    \n",
    "    # Speed statistics\n",
    "    speeds_ms = valid_traj[:, 2]\n",
    "    speeds_kmh = speeds_ms * 3.6\n",
    "    avg_speed = np.mean(speeds_kmh)\n",
    "    std_speed = np.std(speeds_kmh)\n",
    "    max_speed = np.max(speeds_kmh)\n",
    "    \n",
    "    # Distance calculations\n",
    "    if valid_length > 1:\n",
    "        lat_diff = np.diff(valid_traj[:, 0])\n",
    "        lon_diff = np.diff(valid_traj[:, 1])\n",
    "        distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111  # Approximate km\n",
    "        total_distance = np.sum(distances)\n",
    "        \n",
    "        # Bird distance\n",
    "        start = valid_traj[0, :2]\n",
    "        end = valid_traj[-1, :2]\n",
    "        bird_distance = np.sqrt(np.sum((end - start)**2)) * 111\n",
    "    else:\n",
    "        total_distance = 0\n",
    "        bird_distance = 0\n",
    "    \n",
    "    return {\n",
    "        'duration_min': duration_min,\n",
    "        'avg_speed_kmh': avg_speed,\n",
    "        'std_speed_kmh': std_speed,\n",
    "        'max_speed_kmh': max_speed,\n",
    "        'total_distance_km': total_distance,\n",
    "        'bird_distance_km': bird_distance,\n",
    "        'valid_points': valid_length\n",
    "    }\n",
    "\n",
    "def load_all_real_trajectories(preprocessing_dir: Path, transport_mode: str):\n",
    "    \"\"\"Load ALL real trajectories for a transport mode.\"\"\"\n",
    "    # Load interpolated trips\n",
    "    with open(preprocessing_dir / 'interpolated_trips.pkl', 'rb') as f:\n",
    "        interpolated_trips = pickle.load(f)\n",
    "    \n",
    "    # Filter by transport mode\n",
    "    mode_trips = [t for t in interpolated_trips if t['category'] == transport_mode]\n",
    "    \n",
    "    if len(mode_trips) == 0:\n",
    "        print(f\"No trips found for mode: {transport_mode}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(mode_trips)} {transport_mode} trajectories\")\n",
    "    \n",
    "    # Convert all trips\n",
    "    real_trajectories = []\n",
    "    for trip in mode_trips:\n",
    "        # GPS points: [timestamp, lat, lon, speed]\n",
    "        gps_points = trip['gps_points']\n",
    "        # Extract lat, lon, speed\n",
    "        trajectory = gps_points[:, 1:4].astype(np.float32)\n",
    "        \n",
    "        real_trajectories.append({\n",
    "            'trajectory': trajectory,\n",
    "            'trip_id': trip['trip_id'],\n",
    "            'user_id': trip['user_id'],\n",
    "            'category': trip['category'],\n",
    "            'trip_type': trip['trip_type'],\n",
    "            'original_duration': trip['duration_minutes'],\n",
    "            'length': len(trajectory),\n",
    "            'weight': trip.get('weight', 1.0)\n",
    "        })\n",
    "    \n",
    "    return real_trajectories\n",
    "\n",
    "def generate_all_matched_trajectories(\n",
    "    model,\n",
    "    scalers,\n",
    "    real_trajectories: List[Dict],\n",
    "    transport_mode: str,\n",
    "    device: str,\n",
    "    batch_size: int = 32\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Generate trajectories matching all real trajectories' lengths.\"\"\"\n",
    "    \n",
    "    # Extract lengths\n",
    "    trip_lengths = [t['length'] for t in real_trajectories]\n",
    "    \n",
    "    print(f\"\\nGenerating {len(trip_lengths)} {transport_mode} trajectories...\")\n",
    "    \n",
    "    # Generate in batches\n",
    "    gen_trajectories_norm = generate_batch_trajectories(\n",
    "        model, transport_mode, trip_lengths, batch_size, device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units\n",
    "    print(\"Converting to real units...\")\n",
    "    gen_trajectories_real = inverse_transform_simple(gen_trajectories_norm, scalers)\n",
    "    \n",
    "    # Create trajectory info list\n",
    "    generated_trajectories = []\n",
    "    for i, (gen_traj, real_info) in enumerate(zip(gen_trajectories_real, real_trajectories)):\n",
    "        generated_trajectories.append({\n",
    "            'trajectory': gen_traj,\n",
    "            'matched_to': real_info['trip_id'],\n",
    "            'category': transport_mode,\n",
    "            'length': real_info['length'],\n",
    "            'weight': real_info['weight']\n",
    "        })\n",
    "    \n",
    "    return generated_trajectories\n",
    "\n",
    "def compute_aggregate_statistics(trajectories: List[Dict], label: str = \"\") -> Dict:\n",
    "    \"\"\"Compute aggregate statistics for a set of trajectories.\"\"\"\n",
    "    all_metrics = []\n",
    "    total_weight = 0\n",
    "    \n",
    "    for traj_info in trajectories:\n",
    "        metrics = compute_trajectory_metrics(\n",
    "            traj_info['trajectory'], \n",
    "            traj_info.get('length')\n",
    "        )\n",
    "        metrics['weight'] = traj_info.get('weight', 1.0)\n",
    "        all_metrics.append(metrics)\n",
    "        total_weight += metrics['weight']\n",
    "    \n",
    "    # Extract arrays for each metric\n",
    "    durations = np.array([m['duration_min'] for m in all_metrics])\n",
    "    avg_speeds = np.array([m['avg_speed_kmh'] for m in all_metrics])\n",
    "    bird_distances = np.array([m['bird_distance_km'] for m in all_metrics])\n",
    "    total_distances = np.array([m['total_distance_km'] for m in all_metrics])\n",
    "    weights = np.array([m['weight'] for m in all_metrics])\n",
    "    \n",
    "    # Compute weighted statistics\n",
    "    def weighted_mean(values, weights):\n",
    "        return np.sum(values * weights) / np.sum(weights)\n",
    "    \n",
    "    def weighted_std(values, weights):\n",
    "        mean = weighted_mean(values, weights)\n",
    "        variance = weighted_mean((values - mean)**2, weights)\n",
    "        return np.sqrt(variance)\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'n_trajectories': len(trajectories),\n",
    "        'total_weight': total_weight,\n",
    "        'duration_mean': weighted_mean(durations, weights),\n",
    "        'duration_std': weighted_std(durations, weights),\n",
    "        'duration_min': np.min(durations),\n",
    "        'duration_max': np.max(durations),\n",
    "        'speed_mean': weighted_mean(avg_speeds, weights),\n",
    "        'speed_std': weighted_std(avg_speeds, weights),\n",
    "        'speed_min': np.min(avg_speeds),\n",
    "        'speed_max': np.max(avg_speeds),\n",
    "        'bird_distance_mean': weighted_mean(bird_distances, weights),\n",
    "        'bird_distance_std': weighted_std(bird_distances, weights),\n",
    "        'bird_distance_min': np.min(bird_distances),\n",
    "        'bird_distance_max': np.max(bird_distances),\n",
    "        'total_distance_mean': weighted_mean(total_distances, weights),\n",
    "        'total_distance_std': weighted_std(total_distances, weights),\n",
    "        'total_distance_min': np.min(total_distances),\n",
    "        'total_distance_max': np.max(total_distances),\n",
    "    }\n",
    "\n",
    "def print_mode_comparison(mode: str, real_stats: Dict, gen_stats: Dict):\n",
    "    \"\"\"Print detailed comparison for a transport mode.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{mode} COMPARISON\")\n",
    "    print('='*80)\n",
    "    \n",
    "    print(f\"\\nDataset size:\")\n",
    "    print(f\"  Real trajectories: {real_stats['n_trajectories']:,} (weight: {real_stats['total_weight']:,.0f})\")\n",
    "    print(f\"  Generated trajectories: {gen_stats['n_trajectories']:,} (weight: {gen_stats['total_weight']:,.0f})\")\n",
    "    \n",
    "    metrics = [\n",
    "        ('Duration (min)', 'duration'),\n",
    "        ('Speed avg (km/h)', 'speed'),\n",
    "        ('Bird distance (km)', 'bird_distance'),\n",
    "        ('Total distance (km)', 'total_distance')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nMetric comparison (weighted statistics):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric_name, metric_key in metrics:\n",
    "        real_mean = real_stats[f'{metric_key}_mean']\n",
    "        real_std = real_stats[f'{metric_key}_std']\n",
    "        gen_mean = gen_stats[f'{metric_key}_mean']\n",
    "        gen_std = gen_stats[f'{metric_key}_std']\n",
    "        \n",
    "        # Calculate relative error\n",
    "        rel_error = abs(gen_mean - real_mean) / real_mean * 100 if real_mean > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Real:      {real_mean:.2f} ± {real_std:.2f} (range: [{real_stats[f'{metric_key}_min']:.2f}, {real_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Generated: {gen_mean:.2f} ± {gen_std:.2f} (range: [{gen_stats[f'{metric_key}_min']:.2f}, {gen_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Relative Error: {rel_error:.1f}%\")\n",
    "\n",
    "def create_sample_visualization_map(\n",
    "    real_trajectories: List[Dict],\n",
    "    generated_trajectories: List[Dict],\n",
    "    mode: str,\n",
    "    n_samples: int = 10,\n",
    "    output_file: str = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"Create a map with a sample of trajectories for visualization.\"\"\"\n",
    "    # Sample trajectories if needed\n",
    "    if len(real_trajectories) > n_samples:\n",
    "        sample_indices = np.random.choice(len(real_trajectories), n_samples, replace=False)\n",
    "        real_sample = [real_trajectories[i] for i in sample_indices]\n",
    "        gen_sample = [generated_trajectories[i] for i in sample_indices]\n",
    "    else:\n",
    "        real_sample = real_trajectories\n",
    "        gen_sample = generated_trajectories\n",
    "    \n",
    "    # Prepare for visualization\n",
    "    all_trajectories = []\n",
    "    labels = []\n",
    "    types = []\n",
    "    \n",
    "    for i, traj_info in enumerate(real_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Real {mode} {i+1}\")\n",
    "        types.append('real')\n",
    "    \n",
    "    for i, traj_info in enumerate(gen_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Generated {mode} {i+1}\")\n",
    "        types.append('generated')\n",
    "    \n",
    "    # Calculate center\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    for traj in all_trajectories:\n",
    "        valid_mask = ~np.all(traj == 0, axis=1)\n",
    "        all_lats.extend(traj[valid_mask, 0])\n",
    "        all_lons.extend(traj[valid_mask, 1])\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=11)\n",
    "    \n",
    "    # Define colors\n",
    "    real_colors = ['blue', 'darkblue', 'lightblue', 'navy', 'steelblue']\n",
    "    generated_colors = ['red', 'darkred', 'orange', 'pink', 'coral']\n",
    "    \n",
    "    # Add trajectories\n",
    "    for i, (traj, label, traj_type) in enumerate(zip(all_trajectories, labels, types)):\n",
    "        if traj_type == 'real':\n",
    "            color = real_colors[i % len(real_colors)]\n",
    "            line_style = None\n",
    "        else:\n",
    "            color = generated_colors[(i - len(real_sample)) % len(generated_colors)]\n",
    "            line_style = '10'\n",
    "        \n",
    "        # Get valid points\n",
    "        if traj_type == 'generated':\n",
    "            traj_info = gen_sample[i - len(real_sample)]\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "        else:\n",
    "            valid_mask = ~np.all(traj == 0, axis=1)\n",
    "            valid_traj = traj[valid_mask]\n",
    "        \n",
    "        points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "        \n",
    "        # Add polyline\n",
    "        if line_style:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.7,\n",
    "                dash_array=line_style,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "        else:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.8,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 50px; right: 50px; width: 250px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <p style=\"margin: 0;\"><b>{mode} Trajectories</b></p>\n",
    "    <p style=\"margin: 5px 0;\">Sample size: {len(real_sample)} of {len(real_trajectories)} total</p>\n",
    "    <p style=\"margin: 10px 0 5px 0;\"><b>Line styles:</b></p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: blue;\">━━━</span> Real trajectories</p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: red;\">┅┅┅</span> Generated trajectories</p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    if output_file:\n",
    "        m.save(output_file)\n",
    "        print(f\"Sample visualization saved to: {output_file}\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def run_complete_analysis(\n",
    "    checkpoint_dir: Path,\n",
    "    preprocessing_dir: Path,\n",
    "    transport_modes: List[str] = [\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "    batch_size: int = 32,\n",
    "    save_sample_maps: bool = True,\n",
    "    sample_size: int = 10\n",
    "):\n",
    "    \"\"\"Run complete analysis generating trajectories for ALL real trajectories.\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    \n",
    "    # Load scalers\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    \n",
    "    # Storage for results\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each transport mode\n",
    "    for mode in transport_modes:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {mode}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        # Load ALL real trajectories for this mode\n",
    "        real_trajectories = load_all_real_trajectories(preprocessing_dir, mode)\n",
    "        \n",
    "        if len(real_trajectories) == 0:\n",
    "            print(f\"Skipping {mode} - no trajectories found\")\n",
    "            continue\n",
    "        \n",
    "        # Generate matched trajectories for ALL real ones\n",
    "        generated_trajectories = generate_all_matched_trajectories(\n",
    "            model, scalers, real_trajectories, mode, device, batch_size\n",
    "        )\n",
    "        \n",
    "        # Compute aggregate statistics\n",
    "        print(\"\\nComputing statistics...\")\n",
    "        real_stats = compute_aggregate_statistics(real_trajectories, f\"Real {mode}\")\n",
    "        gen_stats = compute_aggregate_statistics(generated_trajectories, f\"Generated {mode}\")\n",
    "        \n",
    "        # Print comparison\n",
    "        print_mode_comparison(mode, real_stats, gen_stats)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mode': mode,\n",
    "            'real_stats': real_stats,\n",
    "            'gen_stats': gen_stats,\n",
    "            'n_trajectories': len(real_trajectories)\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Create sample visualization if requested\n",
    "        if save_sample_maps:\n",
    "            create_sample_visualization_map(\n",
    "                real_trajectories,\n",
    "                generated_trajectories,\n",
    "                mode,\n",
    "                n_samples=sample_size,\n",
    "                output_file=f\"{mode.lower()}_sample_trajectories.html\"\n",
    "            )\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY ACROSS ALL MODES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in all_results:\n",
    "        mode = result['mode']\n",
    "        real_stats = result['real_stats']\n",
    "        gen_stats = result['gen_stats']\n",
    "        \n",
    "        for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "            summary_data.append({\n",
    "                'transport_mode': mode,\n",
    "                'metric': metric,\n",
    "                'real_mean': real_stats[f'{metric}_mean'],\n",
    "                'real_std': real_stats[f'{metric}_std'],\n",
    "                'generated_mean': gen_stats[f'{metric}_mean'],\n",
    "                'generated_std': gen_stats[f'{metric}_std'],\n",
    "                'n_samples': result['n_trajectories'],\n",
    "                'relative_error': abs(gen_stats[f'{metric}_mean'] - real_stats[f'{metric}_mean']) / real_stats[f'{metric}_mean'] * 100 if real_stats[f'{metric}_mean'] > 0 else 0\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('all_trajectories_comparison.csv', index=False)\n",
    "    print(f\"\\nComplete comparison saved to: all_trajectories_comparison.csv\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nOverall Performance Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    metric_names = {\n",
    "        'duration': 'Duration (min)',\n",
    "        'speed': 'Speed (km/h)',\n",
    "        'bird_distance': 'Bird Distance (km)',\n",
    "        'total_distance': 'Total Distance (km)'\n",
    "    }\n",
    "    \n",
    "    for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "        metric_data = summary_df[summary_df['metric'] == metric]\n",
    "        avg_error = metric_data['relative_error'].mean()\n",
    "        print(f\"{metric_names[metric]}: Average relative error = {avg_error:.1f}%\")\n",
    "    \n",
    "    return summary_df, all_results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed\")\n",
    "    \n",
    "    # Run complete analysis for ALL trajectories\n",
    "    summary_df, results = run_complete_analysis(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        preprocessing_dir=preprocessing_dir,\n",
    "        transport_modes=[\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "        batch_size=32,  # Process in batches for efficiency\n",
    "        save_sample_maps=True,  # Save sample visualizations\n",
    "        sample_size=10  # Number of trajectories to show in sample maps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a02bcf-f42c-4b55-b8e2-89d176b603e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c67501a-0671-4e0e-bc03-bb2264cee5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Loading model...\n",
      "Loading scalers...\n",
      "\n",
      "================================================================================\n",
      "Processing CAR\n",
      "================================================================================\n",
      "Found 25169 CAR trajectories\n",
      "\n",
      "Generating 25169 CAR trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "CAR COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 25,169 (weight: 10,835,238)\n",
      "  Generated trajectories: 25,169 (weight: 10,835,238)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      19.93 ± 17.29 (range: [0.07, 171.03])\n",
      "  Generated: 19.93 ± 17.29 (range: [0.07, 171.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      91.69 ± 57.93 (range: [0.02, 281.99])\n",
      "  Generated: 12.67 ± 3.15 (range: [5.07, 30.86])\n",
      "  Relative Error: 86.2%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      8.41 ± 11.45 (range: [0.00, 135.00])\n",
      "  Generated: 3.48 ± 3.23 (range: [0.01, 36.39])\n",
      "  Relative Error: 58.6%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      12.61 ± 15.71 (range: [0.00, 168.18])\n",
      "  Generated: 6.68 ± 5.14 (range: [0.99, 85.28])\n",
      "  Relative Error: 47.1%\n",
      "Sample visualization saved to: car_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing WALKING\n",
      "================================================================================\n",
      "Found 19948 WALKING trajectories\n",
      "\n",
      "Generating 19948 WALKING trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "WALKING COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 19,948 (weight: 8,243,547)\n",
      "  Generated trajectories: 19,948 (weight: 8,243,547)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      12.44 ± 13.14 (range: [0.07, 165.03])\n",
      "  Generated: 12.44 ± 13.14 (range: [0.07, 165.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      11.96 ± 9.54 (range: [0.00, 269.81])\n",
      "  Generated: 2.35 ± 0.41 (range: [-3.92, 7.27])\n",
      "  Relative Error: 80.4%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      0.68 ± 1.04 (range: [0.00, 29.64])\n",
      "  Generated: 2.41 ± 2.60 (range: [0.03, 37.41])\n",
      "  Relative Error: 256.2%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      1.40 ± 2.10 (range: [0.00, 64.07])\n",
      "  Generated: 3.74 ± 2.49 (range: [0.37, 42.43])\n",
      "  Relative Error: 167.7%\n",
      "Sample visualization saved to: walking_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing MIXED\n",
      "================================================================================\n",
      "Found 7526 MIXED trajectories\n",
      "\n",
      "Generating 7526 MIXED trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "MIXED COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 7,526 (weight: 3,040,184)\n",
      "  Generated trajectories: 7,526 (weight: 3,040,184)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      49.33 ± 28.16 (range: [0.07, 173.00])\n",
      "  Generated: 49.33 ± 28.16 (range: [0.07, 173.00])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      64.13 ± 44.12 (range: [0.09, 284.54])\n",
      "  Generated: 10.23 ± 3.22 (range: [3.68, 26.31])\n",
      "  Relative Error: 84.0%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      15.93 ± 15.13 (range: [0.00, 150.02])\n",
      "  Generated: 2.79 ± 2.43 (range: [0.04, 34.20])\n",
      "  Relative Error: 82.5%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      21.80 ± 19.46 (range: [0.00, 208.20])\n",
      "  Generated: 8.13 ± 8.24 (range: [0.92, 88.39])\n",
      "  Relative Error: 62.7%\n",
      "Sample visualization saved to: mixed_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing BIKE\n",
      "================================================================================\n",
      "Found 5979 BIKE trajectories\n",
      "\n",
      "Generating 5979 BIKE trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "BIKE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 5,979 (weight: 2,269,561)\n",
      "  Generated trajectories: 5,979 (weight: 2,269,561)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      19.93 ± 17.14 (range: [0.17, 153.03])\n",
      "  Generated: 19.93 ± 17.14 (range: [0.17, 153.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      38.79 ± 18.65 (range: [0.07, 148.33])\n",
      "  Generated: 5.53 ± 0.70 (range: [-3.26, 13.82])\n",
      "  Relative Error: 85.7%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      3.92 ± 4.42 (range: [0.00, 58.75])\n",
      "  Generated: 1.75 ± 1.87 (range: [0.02, 37.91])\n",
      "  Relative Error: 55.5%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      5.82 ± 6.31 (range: [0.00, 76.82])\n",
      "  Generated: 3.51 ± 2.76 (range: [0.84, 40.78])\n",
      "  Relative Error: 39.7%\n",
      "Sample visualization saved to: bike_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Processing PUBLIC_TRANSPORT\n",
      "================================================================================\n",
      "Found 9432 PUBLIC_TRANSPORT trajectories\n",
      "\n",
      "Generating 9432 PUBLIC_TRANSPORT trajectories...\n",
      "Converting to real units...\n",
      "\n",
      "Computing statistics...\n",
      "\n",
      "================================================================================\n",
      "PUBLIC_TRANSPORT COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Dataset size:\n",
      "  Real trajectories: 9,432 (weight: 4,019,902)\n",
      "  Generated trajectories: 9,432 (weight: 4,019,902)\n",
      "\n",
      "Metric comparison (weighted statistics):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Duration (min):\n",
      "  Real:      29.36 ± 22.16 (range: [0.03, 179.03])\n",
      "  Generated: 29.36 ± 22.16 (range: [0.03, 179.03])\n",
      "  Relative Error: 0.0%\n",
      "\n",
      "Speed avg (km/h):\n",
      "  Real:      35.89 ± 33.64 (range: [0.07, 470.56])\n",
      "  Generated: 5.90 ± 2.29 (range: [2.93, 24.95])\n",
      "  Relative Error: 83.6%\n",
      "\n",
      "Bird distance (km):\n",
      "  Real:      5.89 ± 7.92 (range: [0.00, 91.79])\n",
      "  Generated: 2.03 ± 2.13 (range: [0.00, 32.03])\n",
      "  Relative Error: 65.5%\n",
      "\n",
      "Total distance (km):\n",
      "  Real:      8.79 ± 11.36 (range: [0.00, 146.82])\n",
      "  Generated: 4.35 ± 4.16 (range: [0.00, 83.02])\n",
      "  Relative Error: 50.5%\n",
      "Sample visualization saved to: public_transport_sample_trajectories.html\n",
      "\n",
      "================================================================================\n",
      "Creating combined map with all generated trajectories...\n",
      "================================================================================\n",
      "Creating map with 2500 generated trajectories\n",
      "All generated trajectories visualization saved to: all_generated_trajectories.html\n",
      "\n",
      "Visualization Summary:\n",
      "  CAR: 500 trajectories displayed (of 25,169 total)\n",
      "  WALKING: 500 trajectories displayed (of 19,948 total)\n",
      "  MIXED: 500 trajectories displayed (of 7,526 total)\n",
      "  BIKE: 500 trajectories displayed (of 5,979 total)\n",
      "  PUBLIC_TRANSPORT: 500 trajectories displayed (of 9,432 total)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY ACROSS ALL MODES\n",
      "================================================================================\n",
      "\n",
      "Complete comparison saved to: all_trajectories_comparison.csv\n",
      "\n",
      "Overall Performance Summary:\n",
      "------------------------------------------------------------\n",
      "Duration (min): Average relative error = 0.0%\n",
      "Speed (km/h): Average relative error = 84.0%\n",
      "Bird Distance (km): Average relative error = 103.7%\n",
      "Total Distance (km): Average relative error = 73.5%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import folium\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Import generation functions from the fixed script\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_batch_trajectories(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    trip_lengths: List[int],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate multiple trajectories in batches for efficiency.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    all_trajectories = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(trip_lengths), batch_size):\n",
    "        batch_lengths = trip_lengths[i:i+batch_size]\n",
    "        batch_size_actual = len(batch_lengths)\n",
    "        \n",
    "        # Cap lengths at model max\n",
    "        batch_lengths = [min(l, 2000) for l in batch_lengths]\n",
    "        \n",
    "        # Create tensors\n",
    "        mode_tensor = torch.full((batch_size_actual,), mode_idx, dtype=torch.long).to(device)\n",
    "        length_tensor = torch.tensor(batch_lengths, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            batch_trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "        \n",
    "        all_trajectories.append(batch_trajectories.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    return np.vstack(all_trajectories) if all_trajectories else np.array([])\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\"\"\"\n",
    "    if isinstance(scaler, dict):\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    if len(trajectories.shape) == 2:\n",
    "        # Single trajectory\n",
    "        return trajectory_scaler.inverse_transform(trajectories)\n",
    "    else:\n",
    "        # Multiple trajectories\n",
    "        n_samples, seq_len, n_features = trajectories.shape\n",
    "        traj_flat = trajectories.reshape(-1, n_features)\n",
    "        traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "        return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_trajectory_metrics(trajectory: np.ndarray, valid_length: Optional[int] = None) -> Dict:\n",
    "    \"\"\"Compute metrics for a single trajectory.\"\"\"\n",
    "    if valid_length is None:\n",
    "        # Find valid length by checking for zero padding\n",
    "        valid_mask = ~np.all(trajectory == 0, axis=1)\n",
    "        valid_length = np.sum(valid_mask)\n",
    "    \n",
    "    # Get valid portion\n",
    "    valid_traj = trajectory[:valid_length]\n",
    "    \n",
    "    # Duration in minutes (2 seconds per point)\n",
    "    duration_min = valid_length * 2 / 60\n",
    "    \n",
    "    # Speed statistics\n",
    "    speeds_ms = valid_traj[:, 2]\n",
    "    speeds_kmh = speeds_ms * 3.6\n",
    "    avg_speed = np.mean(speeds_kmh)\n",
    "    std_speed = np.std(speeds_kmh)\n",
    "    max_speed = np.max(speeds_kmh)\n",
    "    \n",
    "    # Distance calculations\n",
    "    if valid_length > 1:\n",
    "        lat_diff = np.diff(valid_traj[:, 0])\n",
    "        lon_diff = np.diff(valid_traj[:, 1])\n",
    "        distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111  # Approximate km\n",
    "        total_distance = np.sum(distances)\n",
    "        \n",
    "        # Bird distance\n",
    "        start = valid_traj[0, :2]\n",
    "        end = valid_traj[-1, :2]\n",
    "        bird_distance = np.sqrt(np.sum((end - start)**2)) * 111\n",
    "    else:\n",
    "        total_distance = 0\n",
    "        bird_distance = 0\n",
    "    \n",
    "    return {\n",
    "        'duration_min': duration_min,\n",
    "        'avg_speed_kmh': avg_speed,\n",
    "        'std_speed_kmh': std_speed,\n",
    "        'max_speed_kmh': max_speed,\n",
    "        'total_distance_km': total_distance,\n",
    "        'bird_distance_km': bird_distance,\n",
    "        'valid_points': valid_length\n",
    "    }\n",
    "\n",
    "def load_all_real_trajectories(preprocessing_dir: Path, transport_mode: str):\n",
    "    \"\"\"Load ALL real trajectories for a transport mode.\"\"\"\n",
    "    # Load interpolated trips\n",
    "    with open(preprocessing_dir / 'interpolated_trips.pkl', 'rb') as f:\n",
    "        interpolated_trips = pickle.load(f)\n",
    "    \n",
    "    # Filter by transport mode\n",
    "    mode_trips = [t for t in interpolated_trips if t['category'] == transport_mode]\n",
    "    \n",
    "    if len(mode_trips) == 0:\n",
    "        print(f\"No trips found for mode: {transport_mode}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(mode_trips)} {transport_mode} trajectories\")\n",
    "    \n",
    "    # Convert all trips\n",
    "    real_trajectories = []\n",
    "    for trip in mode_trips:\n",
    "        # GPS points: [timestamp, lat, lon, speed]\n",
    "        gps_points = trip['gps_points']\n",
    "        # Extract lat, lon, speed\n",
    "        trajectory = gps_points[:, 1:4].astype(np.float32)\n",
    "        \n",
    "        real_trajectories.append({\n",
    "            'trajectory': trajectory,\n",
    "            'trip_id': trip['trip_id'],\n",
    "            'user_id': trip['user_id'],\n",
    "            'category': trip['category'],\n",
    "            'trip_type': trip['trip_type'],\n",
    "            'original_duration': trip['duration_minutes'],\n",
    "            'length': len(trajectory),\n",
    "            'weight': trip.get('weight', 1.0)\n",
    "        })\n",
    "    \n",
    "    return real_trajectories\n",
    "\n",
    "def generate_all_matched_trajectories(\n",
    "    model,\n",
    "    scalers,\n",
    "    real_trajectories: List[Dict],\n",
    "    transport_mode: str,\n",
    "    device: str,\n",
    "    batch_size: int = 32\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Generate trajectories matching all real trajectories' lengths.\"\"\"\n",
    "    \n",
    "    # Extract lengths\n",
    "    trip_lengths = [t['length'] for t in real_trajectories]\n",
    "    \n",
    "    print(f\"\\nGenerating {len(trip_lengths)} {transport_mode} trajectories...\")\n",
    "    \n",
    "    # Generate in batches\n",
    "    gen_trajectories_norm = generate_batch_trajectories(\n",
    "        model, transport_mode, trip_lengths, batch_size, device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units\n",
    "    print(\"Converting to real units...\")\n",
    "    gen_trajectories_real = inverse_transform_simple(gen_trajectories_norm, scalers)\n",
    "    \n",
    "    # Create trajectory info list\n",
    "    generated_trajectories = []\n",
    "    for i, (gen_traj, real_info) in enumerate(zip(gen_trajectories_real, real_trajectories)):\n",
    "        generated_trajectories.append({\n",
    "            'trajectory': gen_traj,\n",
    "            'matched_to': real_info['trip_id'],\n",
    "            'category': transport_mode,\n",
    "            'length': real_info['length'],\n",
    "            'weight': real_info['weight']\n",
    "        })\n",
    "    \n",
    "    return generated_trajectories\n",
    "\n",
    "def compute_aggregate_statistics(trajectories: List[Dict], label: str = \"\") -> Dict:\n",
    "    \"\"\"Compute aggregate statistics for a set of trajectories.\"\"\"\n",
    "    all_metrics = []\n",
    "    total_weight = 0\n",
    "    \n",
    "    for traj_info in trajectories:\n",
    "        metrics = compute_trajectory_metrics(\n",
    "            traj_info['trajectory'], \n",
    "            traj_info.get('length')\n",
    "        )\n",
    "        metrics['weight'] = traj_info.get('weight', 1.0)\n",
    "        all_metrics.append(metrics)\n",
    "        total_weight += metrics['weight']\n",
    "    \n",
    "    # Extract arrays for each metric\n",
    "    durations = np.array([m['duration_min'] for m in all_metrics])\n",
    "    avg_speeds = np.array([m['avg_speed_kmh'] for m in all_metrics])\n",
    "    bird_distances = np.array([m['bird_distance_km'] for m in all_metrics])\n",
    "    total_distances = np.array([m['total_distance_km'] for m in all_metrics])\n",
    "    weights = np.array([m['weight'] for m in all_metrics])\n",
    "    \n",
    "    # Compute weighted statistics\n",
    "    def weighted_mean(values, weights):\n",
    "        return np.sum(values * weights) / np.sum(weights)\n",
    "    \n",
    "    def weighted_std(values, weights):\n",
    "        mean = weighted_mean(values, weights)\n",
    "        variance = weighted_mean((values - mean)**2, weights)\n",
    "        return np.sqrt(variance)\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'n_trajectories': len(trajectories),\n",
    "        'total_weight': total_weight,\n",
    "        'duration_mean': weighted_mean(durations, weights),\n",
    "        'duration_std': weighted_std(durations, weights),\n",
    "        'duration_min': np.min(durations),\n",
    "        'duration_max': np.max(durations),\n",
    "        'speed_mean': weighted_mean(avg_speeds, weights),\n",
    "        'speed_std': weighted_std(avg_speeds, weights),\n",
    "        'speed_min': np.min(avg_speeds),\n",
    "        'speed_max': np.max(avg_speeds),\n",
    "        'bird_distance_mean': weighted_mean(bird_distances, weights),\n",
    "        'bird_distance_std': weighted_std(bird_distances, weights),\n",
    "        'bird_distance_min': np.min(bird_distances),\n",
    "        'bird_distance_max': np.max(bird_distances),\n",
    "        'total_distance_mean': weighted_mean(total_distances, weights),\n",
    "        'total_distance_std': weighted_std(total_distances, weights),\n",
    "        'total_distance_min': np.min(total_distances),\n",
    "        'total_distance_max': np.max(total_distances),\n",
    "    }\n",
    "\n",
    "def print_mode_comparison(mode: str, real_stats: Dict, gen_stats: Dict):\n",
    "    \"\"\"Print detailed comparison for a transport mode.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{mode} COMPARISON\")\n",
    "    print('='*80)\n",
    "    \n",
    "    print(f\"\\nDataset size:\")\n",
    "    print(f\"  Real trajectories: {real_stats['n_trajectories']:,} (weight: {real_stats['total_weight']:,.0f})\")\n",
    "    print(f\"  Generated trajectories: {gen_stats['n_trajectories']:,} (weight: {gen_stats['total_weight']:,.0f})\")\n",
    "    \n",
    "    metrics = [\n",
    "        ('Duration (min)', 'duration'),\n",
    "        ('Speed avg (km/h)', 'speed'),\n",
    "        ('Bird distance (km)', 'bird_distance'),\n",
    "        ('Total distance (km)', 'total_distance')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nMetric comparison (weighted statistics):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric_name, metric_key in metrics:\n",
    "        real_mean = real_stats[f'{metric_key}_mean']\n",
    "        real_std = real_stats[f'{metric_key}_std']\n",
    "        gen_mean = gen_stats[f'{metric_key}_mean']\n",
    "        gen_std = gen_stats[f'{metric_key}_std']\n",
    "        \n",
    "        # Calculate relative error\n",
    "        rel_error = abs(gen_mean - real_mean) / real_mean * 100 if real_mean > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Real:      {real_mean:.2f} ± {real_std:.2f} (range: [{real_stats[f'{metric_key}_min']:.2f}, {real_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Generated: {gen_mean:.2f} ± {gen_std:.2f} (range: [{gen_stats[f'{metric_key}_min']:.2f}, {gen_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Relative Error: {rel_error:.1f}%\")\n",
    "\n",
    "def create_sample_visualization_map(\n",
    "    real_trajectories: List[Dict],\n",
    "    generated_trajectories: List[Dict],\n",
    "    mode: str,\n",
    "    n_samples: int = 10,\n",
    "    output_file: str = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"Create a map with a sample of trajectories for visualization.\"\"\"\n",
    "    # Sample trajectories if needed\n",
    "    if len(real_trajectories) > n_samples:\n",
    "        sample_indices = np.random.choice(len(real_trajectories), n_samples, replace=False)\n",
    "        real_sample = [real_trajectories[i] for i in sample_indices]\n",
    "        gen_sample = [generated_trajectories[i] for i in sample_indices]\n",
    "    else:\n",
    "        real_sample = real_trajectories\n",
    "        gen_sample = generated_trajectories\n",
    "    \n",
    "    # Prepare for visualization\n",
    "    all_trajectories = []\n",
    "    labels = []\n",
    "    types = []\n",
    "    \n",
    "    for i, traj_info in enumerate(real_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Real {mode} {i+1}\")\n",
    "        types.append('real')\n",
    "    \n",
    "    for i, traj_info in enumerate(gen_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Generated {mode} {i+1}\")\n",
    "        types.append('generated')\n",
    "    \n",
    "    # Calculate center\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    for traj in all_trajectories:\n",
    "        valid_mask = ~np.all(traj == 0, axis=1)\n",
    "        all_lats.extend(traj[valid_mask, 0])\n",
    "        all_lons.extend(traj[valid_mask, 1])\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=11)\n",
    "    \n",
    "    # Define colors\n",
    "    real_colors = ['blue', 'darkblue', 'lightblue', 'navy', 'steelblue']\n",
    "    generated_colors = ['red', 'darkred', 'orange', 'pink', 'coral']\n",
    "    \n",
    "    # Add trajectories\n",
    "    for i, (traj, label, traj_type) in enumerate(zip(all_trajectories, labels, types)):\n",
    "        if traj_type == 'real':\n",
    "            color = real_colors[i % len(real_colors)]\n",
    "            line_style = None\n",
    "        else:\n",
    "            color = generated_colors[(i - len(real_sample)) % len(generated_colors)]\n",
    "            line_style = '10'\n",
    "        \n",
    "        # Get valid points\n",
    "        if traj_type == 'generated':\n",
    "            traj_info = gen_sample[i - len(real_sample)]\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "        else:\n",
    "            valid_mask = ~np.all(traj == 0, axis=1)\n",
    "            valid_traj = traj[valid_mask]\n",
    "        \n",
    "        points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "        \n",
    "        # Add polyline\n",
    "        if line_style:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.7,\n",
    "                dash_array=line_style,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "        else:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.8,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 50px; right: 50px; width: 250px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <p style=\"margin: 0;\"><b>{mode} Trajectories</b></p>\n",
    "    <p style=\"margin: 5px 0;\">Sample size: {len(real_sample)} of {len(real_trajectories)} total</p>\n",
    "    <p style=\"margin: 10px 0 5px 0;\"><b>Line styles:</b></p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: blue;\">━━━</span> Real trajectories</p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: red;\">┅┅┅</span> Generated trajectories</p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    if output_file:\n",
    "        m.save(output_file)\n",
    "        print(f\"Sample visualization saved to: {output_file}\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def create_all_generated_trajectories_map(\n",
    "    all_generated_trajectories: Dict[str, List[Dict]],\n",
    "    output_file: str = \"all_generated_trajectories.html\",\n",
    "    max_trajectories_per_mode: int = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"\n",
    "    Create a map with ALL generated trajectories, colored by transport type.\n",
    "    \n",
    "    Args:\n",
    "        all_generated_trajectories: Dict with transport mode as key and list of trajectory dicts as value\n",
    "        output_file: Path to save the HTML file\n",
    "        max_trajectories_per_mode: Optional limit on trajectories per mode (for performance)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define colors for each transport mode\n",
    "    mode_colors = {\n",
    "        'CAR': '#FF0000',        # Red\n",
    "        'WALKING': '#00FF00',    # Green\n",
    "        'BIKE': '#0000FF',       # Blue\n",
    "        'PUBLIC_TRANSPORT': '#FF00FF',  # Magenta\n",
    "        'MIXED': '#FFA500'       # Orange\n",
    "    }\n",
    "    \n",
    "    # Collect all trajectories with their modes\n",
    "    all_trajectories = []\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    \n",
    "    total_trajectories = 0\n",
    "    for mode, trajectories in all_generated_trajectories.items():\n",
    "        if len(trajectories) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Limit trajectories per mode if specified\n",
    "        mode_trajectories = trajectories\n",
    "        if max_trajectories_per_mode and len(trajectories) > max_trajectories_per_mode:\n",
    "            sample_indices = np.random.choice(len(trajectories), max_trajectories_per_mode, replace=False)\n",
    "            mode_trajectories = [trajectories[i] for i in sample_indices]\n",
    "        \n",
    "        for i, traj_info in enumerate(mode_trajectories):\n",
    "            traj = traj_info['trajectory']\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "            \n",
    "            # Extract coordinates\n",
    "            points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "            if len(points) > 1:  # Only add trajectories with more than 1 point\n",
    "                all_trajectories.append({\n",
    "                    'points': points,\n",
    "                    'mode': mode,\n",
    "                    'color': mode_colors.get(mode, '#808080'),  # Default to gray\n",
    "                    'label': f\"{mode} Trajectory {total_trajectories + 1}\"\n",
    "                })\n",
    "                \n",
    "                # Collect coordinates for centering\n",
    "                lats, lons = zip(*points)\n",
    "                all_lats.extend(lats)\n",
    "                all_lons.extend(lons)\n",
    "                total_trajectories += 1\n",
    "    \n",
    "    print(f\"Creating map with {total_trajectories} generated trajectories\")\n",
    "    \n",
    "    if not all_trajectories:\n",
    "        print(\"No valid trajectories found!\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate center\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=10)\n",
    "    \n",
    "    # Add trajectories\n",
    "    for traj_data in all_trajectories:\n",
    "        folium.PolyLine(\n",
    "            traj_data['points'],\n",
    "            color=traj_data['color'],\n",
    "            weight=2,\n",
    "            opacity=0.7,\n",
    "            popup=traj_data['label']\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Create legend\n",
    "    legend_items = []\n",
    "    mode_counts = {}\n",
    "    for mode, trajectories in all_generated_trajectories.items():\n",
    "        if len(trajectories) > 0:\n",
    "            actual_count = len(trajectories)\n",
    "            displayed_count = min(actual_count, max_trajectories_per_mode) if max_trajectories_per_mode else actual_count\n",
    "            mode_counts[mode] = (displayed_count, actual_count)\n",
    "            color = mode_colors.get(mode, '#808080')\n",
    "            legend_items.append(f'<span style=\"color: {color};\">●</span> {mode}: {displayed_count:,} trajectories')\n",
    "            if max_trajectories_per_mode and actual_count > max_trajectories_per_mode:\n",
    "                legend_items[-1] += f' (of {actual_count:,} total)'\n",
    "    \n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 20px; right: 20px; width: 300px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 15px; border-radius: 5px;\">\n",
    "    <h4 style=\"margin: 0 0 10px 0;\">Generated Trajectories by Transport Mode</h4>\n",
    "    <p style=\"margin: 5px 0;\"><b>Total displayed: {total_trajectories:,} trajectories</b></p>\n",
    "    {'<br>'.join(legend_items)}\n",
    "    <p style=\"margin: 10px 0 0 0; font-size: 12px; color: #666;\">\n",
    "    Click on any trajectory line for details\n",
    "    </p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # Save map\n",
    "    m.save(output_file)\n",
    "    print(f\"All generated trajectories visualization saved to: {output_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nVisualization Summary:\")\n",
    "    for mode, (displayed, total) in mode_counts.items():\n",
    "        print(f\"  {mode}: {displayed:,} trajectories displayed (of {total:,} total)\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def run_complete_analysis(\n",
    "    checkpoint_dir: Path,\n",
    "    preprocessing_dir: Path,\n",
    "    transport_modes: List[str] = [\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "    batch_size: int = 32,\n",
    "    save_sample_maps: bool = True,\n",
    "    sample_size: int = 10,\n",
    "    create_all_trajectories_map: bool = True,\n",
    "    max_trajectories_per_mode: int = 500  # Limit for performance\n",
    "):\n",
    "    \"\"\"Run complete analysis generating trajectories for ALL real trajectories.\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    \n",
    "    # Load scalers\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    \n",
    "    # Storage for results\n",
    "    all_results = []\n",
    "    all_generated_trajectories = {}\n",
    "    \n",
    "    # Process each transport mode\n",
    "    for mode in transport_modes:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {mode}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        # Load ALL real trajectories for this mode\n",
    "        real_trajectories = load_all_real_trajectories(preprocessing_dir, mode)\n",
    "        \n",
    "        if len(real_trajectories) == 0:\n",
    "            print(f\"Skipping {mode} - no trajectories found\")\n",
    "            continue\n",
    "        \n",
    "        # Generate matched trajectories for ALL real ones\n",
    "        generated_trajectories = generate_all_matched_trajectories(\n",
    "            model, scalers, real_trajectories, mode, device, batch_size\n",
    "        )\n",
    "        \n",
    "        # Store generated trajectories for the combined map\n",
    "        all_generated_trajectories[mode] = generated_trajectories\n",
    "        \n",
    "        # Compute aggregate statistics\n",
    "        print(\"\\nComputing statistics...\")\n",
    "        real_stats = compute_aggregate_statistics(real_trajectories, f\"Real {mode}\")\n",
    "        gen_stats = compute_aggregate_statistics(generated_trajectories, f\"Generated {mode}\")\n",
    "        \n",
    "        # Print comparison\n",
    "        print_mode_comparison(mode, real_stats, gen_stats)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mode': mode,\n",
    "            'real_stats': real_stats,\n",
    "            'gen_stats': gen_stats,\n",
    "            'n_trajectories': len(real_trajectories)\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Create sample visualization if requested\n",
    "        if save_sample_maps:\n",
    "            create_sample_visualization_map(\n",
    "                real_trajectories,\n",
    "                generated_trajectories,\n",
    "                mode,\n",
    "                n_samples=sample_size,\n",
    "                output_file=f\"{mode.lower()}_sample_trajectories.html\"\n",
    "            )\n",
    "    \n",
    "    # Create map with ALL generated trajectories\n",
    "    if create_all_trajectories_map and all_generated_trajectories:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Creating combined map with all generated trajectories...\")\n",
    "        print('='*80)\n",
    "        \n",
    "        create_all_generated_trajectories_map(\n",
    "            all_generated_trajectories,\n",
    "            output_file=\"all_generated_trajectories.html\",\n",
    "            max_trajectories_per_mode=max_trajectories_per_mode\n",
    "        )\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY ACROSS ALL MODES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in all_results:\n",
    "        mode = result['mode']\n",
    "        real_stats = result['real_stats']\n",
    "        gen_stats = result['gen_stats']\n",
    "        \n",
    "        for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "            summary_data.append({\n",
    "                'transport_mode': mode,\n",
    "                'metric': metric,\n",
    "                'real_mean': real_stats[f'{metric}_mean'],\n",
    "                'real_std': real_stats[f'{metric}_std'],\n",
    "                'generated_mean': gen_stats[f'{metric}_mean'],\n",
    "                'generated_std': gen_stats[f'{metric}_std'],\n",
    "                'n_samples': result['n_trajectories'],\n",
    "                'relative_error': abs(gen_stats[f'{metric}_mean'] - real_stats[f'{metric}_mean']) / real_stats[f'{metric}_mean'] * 100 if real_stats[f'{metric}_mean'] > 0 else 0\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('all_trajectories_comparison.csv', index=False)\n",
    "    print(f\"\\nComplete comparison saved to: all_trajectories_comparison.csv\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nOverall Performance Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    metric_names = {\n",
    "        'duration': 'Duration (min)',\n",
    "        'speed': 'Speed (km/h)',\n",
    "        'bird_distance': 'Bird Distance (km)',\n",
    "        'total_distance': 'Total Distance (km)'\n",
    "    }\n",
    "    \n",
    "    for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "        metric_data = summary_df[summary_df['metric'] == metric]\n",
    "        avg_error = metric_data['relative_error'].mean()\n",
    "        print(f\"{metric_names[metric]}: Average relative error = {avg_error:.1f}%\")\n",
    "    \n",
    "    return summary_df, all_results, all_generated_trajectories\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed\")\n",
    "    \n",
    "    # Run complete analysis for ALL trajectories\n",
    "    summary_df, results, all_generated = run_complete_analysis(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        preprocessing_dir=preprocessing_dir,\n",
    "        transport_modes=[\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "        batch_size=32,  # Process in batches for efficiency\n",
    "        save_sample_maps=True,  # Save sample visualizations\n",
    "        sample_size=10,  # Number of trajectories to show in sample maps\n",
    "        create_all_trajectories_map=True,  # Create the new combined map\n",
    "        max_trajectories_per_mode=500  # Limit trajectories per mode for performance\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825e983-bb72-4036-8319-bb1a1f59b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
