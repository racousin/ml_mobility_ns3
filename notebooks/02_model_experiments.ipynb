{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiments - Trajectory VAE\n",
    "\n",
    "This notebook demonstrates training and experimenting with the trajectory VAE model using the fake NetMob25 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ml_mobility_ns3 import (\n",
    "    NetMob25Loader,\n",
    "    TrajectoryPreprocessor,\n",
    "    TrajectoryVAE,\n",
    "    VAETrainer,\n",
    "    TrajectoryGenerator,\n",
    ")\n",
    "from ml_mobility_ns3.utils.visualization import (\n",
    "    plot_trajectory,\n",
    "    plot_multiple_trajectories,\n",
    "    plot_training_history,\n",
    "    create_folium_map,\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fake data\n",
    "data_dir = Path(\"../data/fake_netmob25\")\n",
    "if not data_dir.exists():\n",
    "    print(\"Fake data not found! Run 'python generate_fake_data.py' first.\")\n",
    "    raise FileNotFoundError(\"Data directory not found\")\n",
    "\n",
    "loader = NetMob25Loader(data_dir)\n",
    "\n",
    "# Load datasets\n",
    "individuals = loader.load_individuals()\n",
    "trips = loader.load_trips()\n",
    "\n",
    "print(f\"Loaded {len(individuals)} individuals\")\n",
    "print(f\"Loaded {len(trips)} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample trajectories\n",
    "print(\"Sampling trajectories...\")\n",
    "trajectories = loader.sample_trajectories(n_samples=500, min_points=10)\n",
    "print(f\"Sampled {len(trajectories)} valid trajectories\")\n",
    "\n",
    "# Show trajectory length distribution\n",
    "traj_lengths = [len(t) for t in trajectories]\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(traj_lengths, bins=30, alpha=0.7)\n",
    "plt.xlabel('Number of GPS points')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Trajectory Length Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(traj_lengths)\n",
    "plt.ylabel('Number of GPS points')\n",
    "plt.title('Trajectory Length Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean trajectory length: {np.mean(traj_lengths):.1f}\")\n",
    "print(f\"Median trajectory length: {np.median(traj_lengths):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "sequence_length = 30  # Fixed sequence length\n",
    "preprocessor = TrajectoryPreprocessor(sequence_length=sequence_length)\n",
    "\n",
    "# Split data\n",
    "n_train = int(len(trajectories) * 0.7)\n",
    "n_val = int(len(trajectories) * 0.15)\n",
    "\n",
    "train_trajectories = trajectories[:n_train]\n",
    "val_trajectories = trajectories[n_train:n_train+n_val]\n",
    "test_trajectories = trajectories[n_train+n_val:]\n",
    "\n",
    "print(f\"Train: {len(train_trajectories)}\")\n",
    "print(f\"Val: {len(val_trajectories)}\")\n",
    "print(f\"Test: {len(test_trajectories)}\")\n",
    "\n",
    "# Fit preprocessor on training data\n",
    "preprocessor.fit(train_trajectories)\n",
    "\n",
    "# Transform data\n",
    "train_data = preprocessor.transform(train_trajectories)\n",
    "val_data = preprocessor.transform(val_trajectories)\n",
    "test_data = preprocessor.transform(test_trajectories)\n",
    "\n",
    "print(f\"\\nData shapes:\")\n",
    "print(f\"Train: {train_data.shape}\")\n",
    "print(f\"Val: {val_data.shape}\")\n",
    "print(f\"Test: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessed data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Sample trajectory features\n",
    "sample_idx = 0\n",
    "sample_features = train_data[sample_idx]\n",
    "\n",
    "# Plot each feature\n",
    "feature_names = ['Latitude', 'Longitude', 'Time (min)', 'Speed']\n",
    "for i, (ax, name) in enumerate(zip(axes.flat, feature_names)):\n",
    "    ax.plot(sample_features[:, i])\n",
    "    ax.set_xlabel('Sequence index')\n",
    "    ax.set_ylabel(f'{name} (normalized)')\n",
    "    ax.set_title(f'{name} over trajectory')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "model_config = {\n",
    "    'input_dim': 4,  # lat, lon, time, speed\n",
    "    'sequence_length': sequence_length,\n",
    "    'hidden_dim': 64,\n",
    "    'latent_dim': 16,\n",
    "    'num_layers': 2,\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = TrajectoryVAE(**model_config)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = VAETrainer(\n",
    "    model,\n",
    "    device=device,\n",
    "    learning_rate=1e-3,\n",
    "    beta=0.5,  # Beta for KL weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "trainer.fit(\n",
    "    train_data,\n",
    "    val_data,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig = plot_training_history(trainer.history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_tensor = torch.FloatTensor(test_data).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon, mu, logvar = model(test_tensor)\n",
    "    \n",
    "    # Calculate reconstruction error\n",
    "    recon_error = torch.mean((recon - test_tensor) ** 2, dim=(1, 2))\n",
    "    mean_recon_error = recon_error.mean().item()\n",
    "    \n",
    "print(f\"Test reconstruction error: {mean_recon_error:.4f}\")\n",
    "\n",
    "# Plot reconstruction error distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(recon_error.cpu().numpy(), bins=30, alpha=0.7)\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Test Set Reconstruction Error Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some reconstructions\n",
    "n_examples = 3\n",
    "indices = np.random.choice(len(test_data), n_examples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_examples, 2, figsize=(12, 8))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Get original and reconstructed\n",
    "    original = test_data[idx]\n",
    "    with torch.no_grad():\n",
    "        recon_norm = model(torch.FloatTensor(original).unsqueeze(0).to(device))[0]\n",
    "        recon_norm = recon_norm.cpu().numpy()[0]\n",
    "    \n",
    "    # Inverse transform\n",
    "    original_traj = preprocessor.inverse_transform([original])[0]\n",
    "    recon_traj = preprocessor.inverse_transform([recon_norm])[0]\n",
    "    \n",
    "    # Plot trajectories\n",
    "    ax1, ax2 = axes[i]\n",
    "    \n",
    "    # Original\n",
    "    ax1.plot(original_traj[:, 1], original_traj[:, 0], 'b.-', alpha=0.7, label='Original')\n",
    "    ax1.set_title(f'Original Trajectory {idx}')\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Reconstructed\n",
    "    ax2.plot(recon_traj[:, 1], recon_traj[:, 0], 'r.-', alpha=0.7, label='Reconstructed')\n",
    "    ax2.set_title(f'Reconstructed Trajectory {idx}')\n",
    "    ax2.set_xlabel('Longitude')\n",
    "    ax2.set_ylabel('Latitude')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trajectory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generator\n",
    "generator = TrajectoryGenerator(model, preprocessor, device=device)\n",
    "\n",
    "# Generate new trajectories\n",
    "n_generated = 10\n",
    "generated_trajectories = generator.generate(n_samples=n_generated)\n",
    "\n",
    "print(f\"Generated {len(generated_trajectories)} trajectories\")\n",
    "\n",
    "# Convert to DataFrames for visualization\n",
    "generated_dfs = [generator.to_dataframe(traj) for traj in generated_trajectories]\n",
    "\n",
    "# Plot generated trajectories\n",
    "fig = plot_multiple_trajectories(\n",
    "    generated_dfs[:5],\n",
    "    title=\"Generated Trajectories\",\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generated vs original trajectories\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Original trajectories\n",
    "for i in range(min(5, len(test_trajectories))):\n",
    "    traj = test_trajectories[i]\n",
    "    ax1.plot(traj['LONGITUDE'], traj['LATITUDE'], 'o-', alpha=0.6, markersize=3)\n",
    "ax1.set_title('Original Trajectories')\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Generated trajectories\n",
    "for i in range(min(5, len(generated_dfs))):\n",
    "    traj = generated_dfs[i]\n",
    "    ax2.plot(traj['LONGITUDE'], traj['LATITUDE'], 'o-', alpha=0.6, markersize=3)\n",
    "ax2.set_title('Generated Trajectories')\n",
    "ax2.set_xlabel('Longitude')\n",
    "ax2.set_ylabel('Latitude')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Latent Space Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all test trajectories to latent space\n",
    "model.eval()\n",
    "latent_codes = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data), 32):\n",
    "        batch = torch.FloatTensor(test_data[i:i+32]).to(device)\n",
    "        mu, _ = model.encode(batch)\n",
    "        latent_codes.append(mu.cpu().numpy())\n",
    "\n",
    "latent_codes = np.vstack(latent_codes)\n",
    "print(f\"Latent codes shape: {latent_codes.shape}\")\n",
    "\n",
    "# Visualize latent space (first 2 dimensions)\n",
    "if latent_codes.shape[1] >= 2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(latent_codes[:, 0], latent_codes[:, 1], alpha=0.6)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('Latent Space Visualization (First 2 Dimensions)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# If latent dim > 2, use PCA\n",
    "if latent_codes.shape[1] > 2:\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    latent_pca = pca.fit_transform(latent_codes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(latent_pca[:, 0], latent_pca[:, 1], alpha=0.6)\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "    plt.title('Latent Space - PCA Projection')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trajectory Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two random trajectories for interpolation\n",
    "idx1, idx2 = np.random.choice(len(test_trajectories), 2, replace=False)\n",
    "traj1 = test_trajectories[idx1]\n",
    "traj2 = test_trajectories[idx2]\n",
    "\n",
    "# Interpolate\n",
    "n_interpolations = 7\n",
    "interpolated = generator.interpolate(traj1, traj2, n_steps=n_interpolations)\n",
    "\n",
    "# Plot interpolation\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "for i, (ax, traj) in enumerate(zip(axes[:-1], interpolated)):\n",
    "    traj_df = generator.to_dataframe(traj)\n",
    "    ax.plot(traj_df['LONGITUDE'], traj_df['LATITUDE'], 'o-', markersize=4)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_title('Start Trajectory', fontweight='bold')\n",
    "    elif i == n_interpolations - 1:\n",
    "        ax.set_title('End Trajectory', fontweight='bold')\n",
    "    else:\n",
    "        ax.set_title(f'Interpolation {i}')\n",
    "    \n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Trajectory Interpolation in Latent Space', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different beta values\n",
    "beta_values = [0.1, 0.5, 1.0, 2.0]\n",
    "beta_results = []\n",
    "\n",
    "for beta in beta_values:\n",
    "    print(f\"\\nTraining with beta={beta}\")\n",
    "    \n",
    "    # Create new model\n",
    "    model_beta = TrajectoryVAE(**model_config)\n",
    "    trainer_beta = VAETrainer(model_beta, device=device, learning_rate=1e-3, beta=beta)\n",
    "    \n",
    "    # Quick training\n",
    "    trainer_beta.fit(\n",
    "        train_data[:100],  # Use subset for quick experiment\n",
    "        val_data[:20],\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    beta_results.append({\n",
    "        'beta': beta,\n",
    "        'final_loss': trainer_beta.history['train_loss'][-1],\n",
    "        'history': trainer_beta.history\n",
    "    })\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for result in beta_results:\n",
    "    plt.plot(result['history']['train_loss'], label=f'β={result[\"beta\"]}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss for Different β Values')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different latent dimensions\n",
    "latent_dims = [8, 16, 32, 64]\n",
    "latent_results = []\n",
    "\n",
    "for latent_dim in latent_dims:\n",
    "    print(f\"\\nTraining with latent_dim={latent_dim}\")\n",
    "    \n",
    "    # Create model with different latent dimension\n",
    "    config = model_config.copy()\n",
    "    config['latent_dim'] = latent_dim\n",
    "    \n",
    "    model_latent = TrajectoryVAE(**config)\n",
    "    trainer_latent = VAETrainer(model_latent, device=device, learning_rate=1e-3, beta=0.5)\n",
    "    \n",
    "    # Quick training\n",
    "    trainer_latent.fit(\n",
    "        train_data[:100],\n",
    "        val_data[:20],\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    # Generate sample\n",
    "    gen = TrajectoryGenerator(model_latent, preprocessor, device=device)\n",
    "    sample = gen.generate(n_samples=1)[0]\n",
    "    \n",
    "    latent_results.append({\n",
    "        'latent_dim': latent_dim,\n",
    "        'final_loss': trainer_latent.history['train_loss'][-1],\n",
    "        'sample': sample\n",
    "    })\n",
    "\n",
    "# Compare generated samples\n",
    "fig, axes = plt.subplots(1, len(latent_dims), figsize=(16, 4))\n",
    "for ax, result in zip(axes, latent_results):\n",
    "    ax.plot(result['sample'][:, 1], result['sample'][:, 0], 'o-', markersize=4)\n",
    "    ax.set_title(f'Latent Dim = {result[\"latent_dim\"]}')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Generated Trajectories with Different Latent Dimensions', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "output_dir = Path(\"../output/notebook_experiment\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = output_dir / \"best_model.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': model_config,\n",
    "    'preprocessor': preprocessor,\n",
    "    'training_history': trainer.history,\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Save preprocessor separately\n",
    "with open(output_dir / \"preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Save some generated trajectories\n",
    "generated_df = pd.concat(generated_dfs, ignore_index=True)\n",
    "generated_df.to_csv(output_dir / \"generated_trajectories.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(generated_dfs)} generated trajectories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map with original and generated trajectories\n",
    "map_trajectories = []\n",
    "\n",
    "# Add some original trajectories\n",
    "for i in range(min(3, len(test_trajectories))):\n",
    "    traj = test_trajectories[i].copy()\n",
    "    traj['type'] = 'original'\n",
    "    map_trajectories.append(traj)\n",
    "\n",
    "# Add generated trajectories\n",
    "for i in range(min(3, len(generated_dfs))):\n",
    "    traj = generated_dfs[i].copy()\n",
    "    traj['type'] = 'generated'\n",
    "    map_trajectories.append(traj)\n",
    "\n",
    "# Create map\n",
    "m = create_folium_map(map_trajectories)\n",
    "m.save(str(output_dir / \"trajectories_map.html\"))\n",
    "print(f\"Interactive map saved to {output_dir / 'trajectories_map.html'}\")\n",
    "\n",
    "# Display in notebook\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and preprocessed the fake NetMob25 data\n",
    "2. Trained a VAE model for trajectory generation\n",
    "3. Evaluated reconstruction quality\n",
    "4. Generated new realistic trajectories\n",
    "5. Analyzed the latent space representation\n",
    "6. Demonstrated trajectory interpolation\n",
    "7. Experimented with different hyperparameters\n",
    "8. Saved the trained model and results\n",
    "\n",
    "The model successfully learns to generate realistic trajectories that resemble the training data patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
